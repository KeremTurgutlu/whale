{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from ipyexperiments import *\n",
    "from fastai.basic_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../dev\")\n",
    "from data_utils import seed_everything\n",
    "from fastai.train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://unixnme.blogspot.com/2018/07/pytorch-implementation-of-batchnorm.html\n",
    "class AccumulateBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps, momentum, running_mean=None, running_var=None,\n",
    "                 weight=None, bias=None, name=None):\n",
    "        super(AccumulateBatchNorm, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.running_mean = torch.zeros(num_features) if running_mean is None else running_mean\n",
    "        self.running_var = torch.zeros(num_features) if running_var is None else running_var\n",
    "        self.weight = nn.Parameter(torch.randn(num_features, requires_grad=True))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_features, requires_grad=True))\n",
    "        if weight is not None: self.weight.data.copy_(weight)\n",
    "        if bias is not None: self.bias.data.copy_(bias)\n",
    "        self.name = name\n",
    "        self.reset_batch_stats()\n",
    "        self._train()\n",
    "    \n",
    "    def reset_running_stats(self):\n",
    "        self.running_mean = torch.zeros(self.num_features)\n",
    "        self.running_var = torch.ones(self.num_features)\n",
    "            \n",
    "    def reset_batch_stats(self):\n",
    "        \"reset accumulated batch stats, at the end of full batch\"\n",
    "        self.batch_sum = 0.\n",
    "        self.batch_n = 0.\n",
    "        self.batch_sq_sum = 0.\n",
    "        \n",
    "    def update_running_stats(self):\n",
    "        \"updates running mean and var with current stats, at the end of full batch\"\n",
    "        with torch.no_grad():\n",
    "            self.running_mean += (1 - self.momentum)*self.running_mean + self.momentum*self.batch_mean\n",
    "            self.running_var += (1 - self.momentum)*self.running_var + self.momentum*self.batch_var\n",
    "        \n",
    "    def _train(self): self._training = True\n",
    "    def _eval(self): self._training = False\n",
    "        \n",
    "    def _batchnorm(self, x, weight, bias, mean, var, eps):\n",
    "        if len(x.shape) == 4:\n",
    "            x = x - weight.reshape(1,weight.size(0),1,1).contiguous()\n",
    "            x = x / (var.reshape(1,weight.size(0),1,1).contiguous() + eps)\n",
    "            x = weight.reshape(1,weight.size(0),1,1).contiguous()*x + bias.reshape(1,weight.size(0),1,1).contiguous()\n",
    "            return x\n",
    "            \n",
    "        if len(x.shape) == 2:\n",
    "            x = x - mean\n",
    "            x = x / (var + eps)\n",
    "            x = weight*x + bias\n",
    "            return x\n",
    "    \n",
    "    def forward(self, x):      \n",
    "        \"update input (a part of a batch) using batch stats calculated so far\"  \n",
    "        self.batch_sum += x.view(x.size(0), x.size(1), -1).mean(2).sum(0)*x.size(0)\n",
    "        self.batch_sq_sum += x.view(x.size(0), x.size(1), -1).pow(2).mean(2).sum(0)\n",
    "        self.batch_n += x.size(0)\n",
    "        self.batch_mean = self.batch_sum / self.batch_n\n",
    "        self.batch_var = self.batch_sq_sum / self.batch_n - (self.batch_sum / self.batch_n).pow(2)\n",
    "        if self._training: x = self._batchnorm(x, self.weight, self.bias, self.batch_mean, self.batch_var, self.eps)\n",
    "        else: x = self._batchnorm(x, self.weight, self.bias, self.running_mean, self.running_var, self.eps)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"AccumulateBatchNorm({self.num_features}) \\n from {self.name}\" if self.name else\n",
    "                                        f\"AccumulateBatchNorm({self.num_features})\")\n",
    "\n",
    "def convert_to_accbn(m):\n",
    "    \"convert a batchnorm module to accumulated batchnorm\"\n",
    "    num_features = m.num_features\n",
    "    eps = m.eps\n",
    "    momentum = m.momentum\n",
    "    weight = m.weight.data\n",
    "    bias = m.bias.data\n",
    "    running_mean = m.running_mean.data\n",
    "    running_var = m.running_var.data\n",
    "    return AccumulateBatchNorm(num_features, eps, momentum, running_mean, running_var, weight, bias,\n",
    "                               name=m.__repr__()).to(device=next(m.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm2d(nn.BatchNorm2d):\n",
    "    def forward(self, x):\n",
    "        self._check_input_dim(x)\n",
    "        y = x.transpose(0,1)\n",
    "        return_shape = y.shape\n",
    "        y = y.contiguous().view(x.size(1), -1)\n",
    "        mu = y.mean(dim=1)\n",
    "        sigma2 = y.var(dim=1)\n",
    "        if self.training is not True:\n",
    "            y = y - self.running_mean.view(-1, 1)\n",
    "            y = y / (self.running_var.view(-1, 1)**.5 + self.eps)\n",
    "        else:\n",
    "            if self.track_running_stats is True:\n",
    "                with torch.no_grad():\n",
    "                    self.running_mean = (1-self.momentum)*self.running_mean + self.momentum*mu\n",
    "                    self.running_var = (1-self.momentum)*self.running_var + self.momentum*sigma2\n",
    "            y = y - mu.view(-1,1)\n",
    "            y = y / (sigma2.view(-1,1)**.5 + self.eps)\n",
    "\n",
    "        y = self.weight.view(-1, 1) * y + self.bias.view(-1, 1)\n",
    "        return y.view(return_shape).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://unixnme.blogspot.com/2018/07/pytorch-implementation-of-batchnorm.html\n",
    "class AccumulateBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps, momentum, running_mean=None, running_var=None,\n",
    "                 weight=None, bias=None, name=None):\n",
    "        super(AccumulateBatchNorm, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.running_mean = torch.zeros(num_features) if running_mean is None else running_mean\n",
    "        self.running_var = torch.zeros(num_features) if running_var is None else running_var\n",
    "        self.weight = nn.Parameter(torch.randn(num_features, requires_grad=True))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_features, requires_grad=True))\n",
    "        \n",
    "        if weight is not None: self.weight.data.copy_(weight)\n",
    "        if bias is not None: self.bias.data.copy_(bias)\n",
    "        self.name = name\n",
    "        self.reset_batch_stats()\n",
    "        self._train()\n",
    "    \n",
    "    def reset_running_stats(self):\n",
    "        self.running_mean = torch.zeros(self.num_features, requires_grad=False)\n",
    "        self.running_var = torch.ones(self.num_features, requires_grad=False)\n",
    "            \n",
    "    def reset_batch_stats(self):\n",
    "        \"reset accumulated batch stats, at the end of full batch\"\n",
    "        self.batch_sum = 0.\n",
    "        self.batch_n = 0.\n",
    "        self.batch_sq_sum = 0.\n",
    "        \n",
    "    def update_running_stats(self):\n",
    "        \"updates running mean and var with current stats, at the end of full batch\"\n",
    "        with torch.no_grad():\n",
    "            self.running_mean += (1 - self.momentum)*self.running_mean + self.momentum*self.batch_mean\n",
    "            self.running_var += (1 - self.momentum)*self.running_var + self.momentum*self.batch_var\n",
    "        \n",
    "    def _train(self): self._training = True\n",
    "    def _eval(self): self._training = False\n",
    "        \n",
    "    def _batchnorm(self, x, weight, bias, mean, var, eps):\n",
    "        if len(x.shape) == 4:\n",
    "            x = x - weight.reshape(1,weight.size(0),1,1).contiguous()\n",
    "            x = x / (var.reshape(1,weight.size(0),1,1).contiguous() + eps)\n",
    "            x = weight.reshape(1,weight.size(0),1,1).contiguous()*x + bias.reshape(1,weight.size(0),1,1).contiguous()\n",
    "            return x\n",
    "            \n",
    "        if len(x.shape) == 2:\n",
    "            x = x - mean\n",
    "            x = x / (var + eps)\n",
    "            x = weight*x + bias\n",
    "            return x\n",
    "    \n",
    "    def forward(self, x):      \n",
    "        \"update input (a part of a batch) using batch stats calculated so far\"  \n",
    "        self.batch_sum += x.view(x.size(0), x.size(1), -1).sum(0).sum(1)\n",
    "        self.batch_sq_sum += x.view(x.size(0), x.size(1), -1).pow(2).sum(0).sum(1)\n",
    "        self.batch_n += x.size(0)\n",
    "        self.batch_mean = self.batch_sum / self.batch_n\n",
    "        self.batch_var = self.batch_sq_sum / self.batch_n - (self.batch_sum / self.batch_n).pow(2)\n",
    "        if self._training: \n",
    "            x = self._batchnorm(x, self.weight, self.bias, self.batch_mean, self.batch_var, self.eps)\n",
    "        else: \n",
    "            x = self._batchnorm(x, self.weight, self.bias, self.running_mean, self.running_var, self.eps)\n",
    "        return x\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"AccumulateBatchNorm({self.num_features}) \\n from {self.name}\" if self.name else\n",
    "                                        f\"AccumulateBatchNorm({self.num_features})\")\n",
    "\n",
    "def convert_to_accbn(m):\n",
    "    \"convert a batchnorm module to accumulated batchnorm\"\n",
    "    num_features = m.num_features\n",
    "    eps = m.eps\n",
    "    momentum = m.momentum\n",
    "    weight = m.weight.data\n",
    "    bias = m.bias.data\n",
    "    running_mean = m.running_mean.data\n",
    "    running_var = m.running_var.data\n",
    "    return AccumulateBatchNorm(num_features, eps, momentum, running_mean, running_var, weight, bias,\n",
    "                               name=m.__repr__()).to(device=next(m.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1d = torch.randn(2,5)\n",
    "x_2d = torch.randn(2,5,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5473,  0.8692, -2.1071,  3.1666, -0.0432])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d.view(x_1d.size(0), x_1d.size(1), -1).sum(0).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7396, 0.5745, 2.4327, 5.3136, 0.0468])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d.view(x_1d.size(0), x_1d.size(1), -1).pow(2).sum(0).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_2d_mean = x_2d.view(x_2d.size(0),x_2d.size(1), -1).sum(0).sum(1) / x_2d.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24.6057, 28.8694,  9.5203,  6.3791, 22.9881])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d.view(x_2d.size(0),x_2d.size(1), -1).pow(2).sum(0).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 3, 3]), torch.Size([5]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2d.shape, x_2d_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 9])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_2d.view(x_2d.size(0),x_2d.size(1),-1) - x_2d_mean.view(1, -1, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1d = x_1d.transpose(1,0)\n",
    "y_2d = x_2d.transpose(1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 3, 3]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1d.shape, y_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1sum = y_1d.sum(1); y_1sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1sqsum = y_1d.pow(2).sum(1); y_1sqsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2sum = y_2d.sum(1); y_2sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2sqsum = y_2d.pow(2).sum(1); y_2sqsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 2]), torch.Size([5, 2, 3, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d.transpose(1,0).shape, x_2d.transpose(1,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d.transpose(1,0).view(x_1d.size(1), -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), torch.Size([5, 3, 3]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1d.transpose(1,0).mean(1).shape, x_2d.transpose(1,0).mean(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn1d = nn.BatchNorm1d(5)\n",
    "bn2d = nn.BatchNorm2d(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), torch.Size([5]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1d.weight.shape, bn2d.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1933,  0.2306,  0.4430],\n",
       "          [ 0.0933,  0.2022,  0.5498],\n",
       "          [-0.2102, -0.3940,  0.3365]],\n",
       "\n",
       "         [[ 0.2044, -0.4534,  0.8257],\n",
       "          [ 0.1232,  0.1578,  0.0516],\n",
       "          [-0.1546, -0.0856, -0.3281]],\n",
       "\n",
       "         [[ 0.6490,  0.1373, -0.0040],\n",
       "          [-0.2143, -0.8212, -1.2505],\n",
       "          [ 0.7497,  0.6433,  0.5585]],\n",
       "\n",
       "         [[ 0.6396,  0.1425, -0.2499],\n",
       "          [-0.9141,  0.8008,  0.1875],\n",
       "          [-0.3518, -0.2983,  0.4654]],\n",
       "\n",
       "         [[-0.2627,  0.3282,  0.3491],\n",
       "          [-0.1008,  0.2940, -0.1560],\n",
       "          [ 0.4960,  0.0047, -0.4891]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4140, -0.6099,  0.6479],\n",
       "          [-0.5806, -0.5787, -1.1090],\n",
       "          [ 0.0823,  0.4997, -0.2103]],\n",
       "\n",
       "         [[-0.0259,  0.1840,  0.1501],\n",
       "          [ 0.0723, -0.4996,  0.2975],\n",
       "          [-0.1052,  0.0093, -0.4234]],\n",
       "\n",
       "         [[ 0.1410,  0.5116, -0.2740],\n",
       "          [ 0.1002, -0.2856,  0.4605],\n",
       "          [ 0.2911, -0.0958, -1.2968]],\n",
       "\n",
       "         [[-0.3568, -0.5626, -0.7832],\n",
       "          [ 0.0154,  0.5358,  0.6131],\n",
       "          [-0.2935, -0.4333,  0.8433]],\n",
       "\n",
       "         [[-0.0885, -0.1516,  0.3610],\n",
       "          [-0.3781,  0.2295,  0.1936],\n",
       "          [-0.3105, -0.3966,  0.0778]]]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AccumulateBatchNorm(5) \n",
       " from BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.1545,  0.2142,  0.5533],\n",
       "          [-0.0052,  0.1687,  0.7239],\n",
       "          [-0.4898, -0.7832,  0.3832]],\n",
       "\n",
       "         [[ 0.2241, -0.6436,  1.0436],\n",
       "          [ 0.1169,  0.1626,  0.0225],\n",
       "          [-0.2495, -0.1584, -0.4784]],\n",
       "\n",
       "         [[ 0.4537, -0.2258, -0.4134],\n",
       "          [-0.6928, -1.4986, -2.0687],\n",
       "          [ 0.5873,  0.4461,  0.3334]],\n",
       "\n",
       "         [[ 0.3867, -0.0732, -0.4362],\n",
       "          [-1.0507,  0.5359, -0.0315],\n",
       "          [-0.5304, -0.4809,  0.2255]],\n",
       "\n",
       "         [[-0.4586,  0.2433,  0.2681],\n",
       "          [-0.2663,  0.2026, -0.3318],\n",
       "          [ 0.4425, -0.1409, -0.7273]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5070, -1.1281,  0.8805],\n",
       "          [-1.0811, -1.0782, -1.9249],\n",
       "          [-0.0226,  0.6438, -0.4899]],\n",
       "\n",
       "         [[-0.0797,  0.1971,  0.1525],\n",
       "          [ 0.0498, -0.7046,  0.3468],\n",
       "          [-0.1843, -0.0332, -0.6040]],\n",
       "\n",
       "         [[-0.2209,  0.2712, -0.7720],\n",
       "          [-0.2751, -0.7874,  0.2033],\n",
       "          [-0.0216, -0.5353, -2.1302]],\n",
       "\n",
       "         [[-0.5350, -0.7254, -0.9295],\n",
       "          [-0.1908,  0.2907,  0.3622],\n",
       "          [-0.4765, -0.6058,  0.5751]],\n",
       "\n",
       "         [[-0.2516, -0.3266,  0.2822],\n",
       "          [-0.5956,  0.1260,  0.0834],\n",
       "          [-0.5152, -0.6175, -0.0542]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accbn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([0.4783, 0.3075, 0.5985, 0.5343, 0.2943], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(accbn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.SGD(accbn.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.sum(1 - accbn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([-1.6100, -0.7702, -2.3171, -0.9666, -1.3362], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.8000, 1.8000, 1.8000, 1.8000, 1.8000], requires_grad=True)]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(accbn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add update_running_stats and reset_batch_stats in \n",
    "class AccumulateStepper(LearnerCallback):\n",
    "    \"Does accumlated step every nth step by accumulating gradients\"\n",
    "\n",
    "    def __init__(self, learn:Learner, n_step:int = 1, drop_last:bool = False):\n",
    "        super().__init__(learn)\n",
    "        self.n_step,self.drop_last = n_step,drop_last\n",
    "        \n",
    "    def on_train_begin(self, **kwargs):\n",
    "        \"check if loss is reduction\"\n",
    "        if hasattr(self.loss_func, \"reduction\") and (self.loss_func.reduction != \"sum\"):\n",
    "             warn(\"For better gradients consider 'reduction=sum'\")\n",
    "                \n",
    "    def on_epoch_begin(self, **kwargs):\n",
    "        \"init samples and batches, change optimizer\"\n",
    "        self.acc_samples, self.acc_batches = 0., 0. \n",
    "        \n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        \"accumulate samples and batches\"\n",
    "        self.acc_samples += last_input.shape[0]\n",
    "        self.acc_batches += 1    \n",
    "\n",
    "    def on_backward_end(self, **kwargs):\n",
    "        \"accumulated step and reset samples, True will result in no stepping\"\n",
    "        if (self.acc_batches % self.n_step) == 0:\n",
    "            # do step\n",
    "            for p in (self.learn.model.parameters()):\n",
    "                if p.requires_grad: p.grad.div_(self.acc_samples)\n",
    "            self.acc_samples = 0\n",
    "            # update and reset AccumulateBatchNorm \n",
    "            for g in self.learn.layer_groups:\n",
    "                for l in g:\n",
    "                    if isinstance(l, AccumulateBatchNorm):\n",
    "                        l.update_running_stats()\n",
    "                        l.reset_batch_stats()\n",
    "        else: return True\n",
    "    \n",
    "    def on_step_end(self, **kwargs):\n",
    "        \"zero gradients after stepping, True will result in no zeroing\"\n",
    "        return (self.acc_batches % self.n_step) != 0\n",
    "    \n",
    "    def on_epoch_end(self, **kwargs):\n",
    "        \"step the rest of the accumulated grads if not perfectly divisible\"\n",
    "        for p in (self.learn.model.parameters()):\n",
    "                if p.requires_grad: p.grad.div_(self.acc_samples)\n",
    "        if not self.drop_last: self.learn.opt.step()\n",
    "        self.learn.opt.zero_grad()\n",
    "    \n",
    "    def on_train_end(self, **kwargs):\n",
    "        \"put all AccumulateBatchNorm modules to eval\"\n",
    "        for g in self.learn.layer_groups:\n",
    "            for l in g:\n",
    "                if isinstance(l, AccumulateBatchNorm):\n",
    "                    l._eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed everything for reproducibility\n",
    "seed_everything(42)\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "data = ImageDataBunch.from_folder(path, bs=2)\n",
    "# freeze_to(-1) except for BN layers\n",
    "learn = create_cnn(data, models.vgg16_bn, metrics=accuracy,\n",
    "                   callback_fns=[partial(AccumulateStepper, n_step=16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all BN \n",
    "for i,l in enumerate(learn.model[0][0]):\n",
    "    if isinstance(learn.model[0][0][i], bn_types):\n",
    "        learn.model[0][0][i] = convert_to_accbn(learn.model[0][0][i])\n",
    "for i,l in enumerate(learn.model[1]):\n",
    "    if isinstance(learn.model[1][i], bn_types):\n",
    "        learn.model[1][i] = convert_to_accbn(learn.model[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): AccumulateBatchNorm(64) \n",
       "       from BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): AccumulateBatchNorm(64) \n",
       "       from BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): AccumulateBatchNorm(128) \n",
       "       from BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (9): ReLU(inplace)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): AccumulateBatchNorm(128) \n",
       "       from BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): ReLU(inplace)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): AccumulateBatchNorm(256) \n",
       "       from BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): ReLU(inplace)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): AccumulateBatchNorm(256) \n",
       "       from BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (19): ReLU(inplace)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): AccumulateBatchNorm(256) \n",
       "       from BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (22): ReLU(inplace)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): AccumulateBatchNorm(512) \n",
       "       from BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (26): ReLU(inplace)\n",
       "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): AccumulateBatchNorm(512) \n",
       "       from BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (29): ReLU(inplace)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): AccumulateBatchNorm(512) \n",
       "       from BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (32): ReLU(inplace)\n",
       "      (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): AccumulateBatchNorm(512) \n",
       "       from BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (36): ReLU(inplace)\n",
       "      (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (38): AccumulateBatchNorm(512) \n",
       "       from BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (39): ReLU(inplace)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): AccumulateBatchNorm(512) \n",
       "       from BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (42): ReLU(inplace)\n",
       "      (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): AccumulateBatchNorm(1024) \n",
       "     from BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): AccumulateBatchNorm(512) \n",
       "     from BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreate layer_groups and remove self.opt to force create_opt\n",
    "splits = split_model_idx(learn.model, [22,44]) \n",
    "learn.split(splits)\n",
    "del learn.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = learn.loss_func = CrossEntropyFlat(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type AccumulateBatchNorm. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-d81c6bd29d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/fastai/train.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=False, clip:float=None,\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 179\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/utils/mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             if (\"CUDA out of memory\" in str(e) or\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_backward_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='6198', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "a leaf Variable that requires grad has been used in an in-place operation.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-8587f3539821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 179\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/utils/mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             if (\"CUDA out of memory\" in str(e) or\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-9ecf96a724b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;34m\"update input (a part of a batch) using batch stats calculated so far\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_sq_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_n\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad has been used in an in-place operation."
     ]
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe use `loss(reduction=\"sum\")` and average before `real_step()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### MNIST batch size = 32, no accumulation\n",
    "\n",
    "`effective batch size = 32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# seed everything for reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "data = ImageDataBunch.from_folder(path, bs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet18, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyFlat(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:07 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.141535</th>\n",
       "    <th>0.079934</th>\n",
       "    <th>0.972031</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST batch size=4, accumulate every n_step=8, Default\n",
    "\n",
    "`effective batch size = 32 (bs x n_step)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed everything for reproducibility\n",
    "seed_everything(42)\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "data = ImageDataBunch.from_folder(path, bs=2)\n",
    "# freeze_to(-1) except for BN layers\n",
    "learn = create_cnn(data, models.vgg16_bn, metrics=accuracy,\n",
    "                   callback_fns=[partial(AccumulateStepper, n_step=16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyFlat(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(m[0][0].children()):\n",
    "    if isinstance(m[0][0][i], bn_types):\n",
    "        l = m[0][0][i]\n",
    "        m[0][0][i] = AccumulateBatchNorm(l.__class__, l.num_features).cuda()\n",
    "\n",
    "for i, _ in enumerate(m[1].children()):\n",
    "    if isinstance(m[1][i], bn_types):\n",
    "        l = m[1][i]\n",
    "        m[1][i] = AccumulateBatchNorm(l.__class__, l.num_features).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): ReLU(inplace)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): ReLU(inplace)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (9): ReLU(inplace)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (12): ReLU(inplace)\n",
       "      (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (16): ReLU(inplace)\n",
       "      (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (19): ReLU(inplace)\n",
       "      (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (21): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (22): ReLU(inplace)\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (26): ReLU(inplace)\n",
       "      (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (28): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (29): ReLU(inplace)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (32): ReLU(inplace)\n",
       "      (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (36): ReLU(inplace)\n",
       "      (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (38): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (39): ReLU(inplace)\n",
       "      (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (41): AccumulateBatchNorm(\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (42): ReLU(inplace)\n",
       "      (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (1): Sequential(\n",
       "    (0): AdaptiveConcatPool2d(\n",
       "      (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "      (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "    )\n",
       "    (1): Flatten()\n",
       "    (2): AccumulateBatchNorm(\n",
       "      (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): Dropout(p=0.25)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): AccumulateBatchNorm(\n",
       "      (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (7): Dropout(p=0.5)\n",
       "    (8): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "</table>\n",
       "\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='progress-bar-interrupted' max='6198', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      Interrupted\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "the derivative for 'running_mean' is not implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-8587f3539821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 177\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/utils/mem.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             if (\"CUDA out of memory\" in str(e) or\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-97-f60dcce958bc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         return F.batch_norm(input,self.bn.running_mean, self.bn.running_var, self.bn.weight, self.bn.bias, \n\u001b[0;32m---> 38\u001b[0;31m             self.training, 0., self.bn.eps)  \n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: the derivative for 'running_mean' is not implemented"
     ]
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST batch size=4, accumulate every n_step=8, BNFreeze\n",
    "\n",
    "`effective batch size = 32 (bs x n_step)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.train import BnFreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnFreeze(LearnerCallback):\n",
    "    \"Freeze moving average statistics in all non-trainable batchnorm layers.\"\n",
    "    def on_train_begin(self, **kwargs:Any)->None:\n",
    "        \"Put bn layers in eval mode just after `model.train()`.\"\n",
    "        set_bn_eval(self.learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed everything for reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "data = ImageDataBunch.from_folder(path, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze_to(-1) including BN layers\n",
    "learn = create_cnn(data, models.resnet18, metrics=accuracy,\n",
    "                   callback_fns=[partial(AccumulateStepper, n_step=16), BnFreeze])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze bn layers\n",
    "for g in learn.layer_groups[:-1]:\n",
    "    for l in g:\n",
    "        if isinstance(l, bn_types): requires_grad(l, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n"
     ]
    }
   ],
   "source": [
    "find_active_bn(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyFlat(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 00:51 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.140334</th>\n",
       "    <th>2.693619</th>\n",
       "    <th>0.601570</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST batch size=4, accumulate every n_step=8, BNFreeze + More momentum\n",
    "\n",
    "`effective batch size = 32 (bs x n_step)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.train import BnFreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnFreeze(LearnerCallback):\n",
    "    \"Freeze moving average statistics in all non-trainable batchnorm layers.\"\n",
    "    def on_train_begin(self, **kwargs:Any)->None:\n",
    "        \"Put bn layers in eval mode just after `model.train()`.\"\n",
    "        set_bn_eval(self.learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed everything for reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "data = ImageDataBunch.from_folder(path, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze_to(-1) including BN layers\n",
    "learn = create_cnn(data, models.resnet18, metrics=accuracy,\n",
    "                   callback_fns=[partial(AccumulateStepper, n_step=16), BnFreeze])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # freeze bn layers\n",
    "# for g in learn.layer_groups[:-1]:\n",
    "#     for l in g:\n",
    "#         if isinstance(l, bn_types): requires_grad(l, False)\n",
    "for g in learn.layer_groups:\n",
    "    for l in g:\n",
    "        if isinstance(l, bn_types): l.momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm1d(1024, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
      "BatchNorm1d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n"
     ]
    }
   ],
   "source": [
    "find_active_bn(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyFlat(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:11 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.153869</th>\n",
       "    <th>411.230682</th>\n",
       "    <th>0.479392</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST batch size=4, accumulate every n_step=8, BNFreeze + Custom Running\n",
    "\n",
    "`effective batch size = 32 (bs x n_step)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed everything for reproducibility\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "data = ImageDataBunch.from_folder(path, bs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet18, metrics=accuracy,\n",
    "                   callback_fns=[partial(AccumulateStepper, n_step=16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyFlat(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 04:41 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>1.543319</th>\n",
       "    <th>1.134782</th>\n",
       "    <th>0.743867</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>1.379197</th>\n",
       "    <th>1.387173</th>\n",
       "    <th>0.564769</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>1.277315</th>\n",
       "    <th>1.233230</th>\n",
       "    <th>0.696762</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>1.208992</th>\n",
       "    <th>1.130871</th>\n",
       "    <th>0.759078</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229],\n",
       "        [-0.1863,  2.2082, -0.6380,  0.4617,  0.2674]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((2, 5));x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = nn.BatchNorm1d(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0.]),\n",
       " tensor([1., 1., 1., 1., 1.]),\n",
       " Parameter containing:\n",
       " tensor([0.2696, 0.4414, 0.2969, 0.8317, 0.1053], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True),\n",
       " 1e-05)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mom = bn.momentum, \n",
    "mean = bn.running_mean\n",
    "var = bn.running_var\n",
    "w = bn.weight\n",
    "b = bn.bias\n",
    "eps = bn.eps\n",
    "\n",
    "mean, var, w, b, eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2696, -0.4414,  0.2969, -0.8314, -0.1053],\n",
       "        [-0.2696,  0.4414, -0.2969,  0.8314,  0.1053]],\n",
       "       grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0352,  0.5475, -0.0945,  0.1621, -0.2004]),\n",
       " tensor([0.5955, 1.5444, 0.7098, 0.5440, 0.9842]),\n",
       " Parameter containing:\n",
       " tensor([0.2696, 0.4414, 0.2969, 0.8317, 0.1053], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True),\n",
       " 1e-05)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mom = bn.momentum, \n",
    "mean = bn.running_mean\n",
    "var = bn.running_var\n",
    "w = bn.weight\n",
    "b = bn.bias\n",
    "eps = bn.eps\n",
    "\n",
    "mean, var, w, b, eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = model[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, tensor([ 2.7681e-03, -2.5769e-02,  2.1254e-07, -8.4605e-02,  2.1121e-08,\n",
       "          4.9691e-04, -2.2408e-02, -1.1582e-07, -4.8239e-03,  2.7507e-07,\n",
       "          3.9582e-02,  3.1994e-02, -3.7490e-02, -1.3716e-06,  6.6002e-03,\n",
       "          4.3782e-03,  6.4797e-02,  1.1176e-01,  3.6002e-02, -7.5075e-02,\n",
       "         -3.8240e-02,  8.4358e-02, -5.2287e-02, -1.1799e-02,  1.3019e-03,\n",
       "          3.2172e-02, -1.7784e-02, -9.1009e-02,  1.1319e-01, -4.1632e-02,\n",
       "          8.7302e-03,  2.9693e-02, -7.0502e-02, -3.4847e-03,  1.0977e-01,\n",
       "         -1.7341e-03, -5.9423e-08,  2.9330e-02, -7.8553e-09,  6.7320e-03,\n",
       "         -3.7100e-03,  1.6028e-02, -2.7883e-02,  2.6593e-02,  2.8475e-02,\n",
       "         -1.2735e-01,  4.4617e-02,  2.6329e-02,  2.1454e-08, -1.7045e-02,\n",
       "         -3.5617e-03, -4.5841e-02,  6.3876e-02,  1.5220e-02, -3.8511e-02,\n",
       "         -1.6428e-02, -1.6569e-02,  5.6057e-02, -8.0306e-02, -2.6646e-03,\n",
       "         -4.1718e-02,  1.2611e-01, -4.9237e-02, -1.3261e-02], device='cuda:0'), tensor([1.0169e+00, 3.7167e+00, 5.8133e-11, 3.2825e+00, 1.7107e-13, 6.5823e-01,\n",
       "         4.3701e+00, 6.6005e-12, 9.1552e-01, 1.9318e-09, 4.1256e+00, 2.7440e+00,\n",
       "         2.8391e+00, 4.7966e-08, 1.1072e+01, 5.0075e-01, 2.2313e+00, 4.8257e+00,\n",
       "         2.6986e+00, 9.3700e+00, 3.7339e+00, 5.4843e+00, 5.7127e+00, 4.4544e-01,\n",
       "         4.3628e-01, 7.1563e+00, 1.3718e+01, 5.2512e+00, 6.8174e+00, 1.6724e+00,\n",
       "         1.6534e+00, 1.2325e+00, 4.9076e+00, 3.0731e+00, 4.2384e+00, 4.9936e+00,\n",
       "         1.4465e-12, 1.5212e+00, 1.0352e-13, 3.5134e-01, 1.7025e-01, 1.4205e+00,\n",
       "         1.9085e+00, 2.1512e+00, 2.6608e+00, 4.8444e+00, 1.9297e+00, 1.4999e+00,\n",
       "         2.9481e-13, 1.5306e+00, 3.6503e-01, 2.9376e+00, 5.4664e+00, 7.0792e-01,\n",
       "         3.3315e+00, 7.7180e-01, 2.4068e+00, 6.5214e+00, 4.1263e+00, 1.0506e+00,\n",
       "         2.9530e+00, 1.1366e+01, 4.7690e+00, 1.6559e+00], device='cuda:0'), Parameter containing:\n",
       " tensor([ 2.3487e-01,  2.6626e-01, -5.1096e-08,  5.1870e-01,  3.4404e-09,\n",
       "          2.2239e-01,  4.2289e-01,  1.3153e-07,  2.5093e-01,  1.5152e-06,\n",
       "          3.1687e-01,  2.5049e-01,  3.7893e-01,  1.0862e-05,  2.7526e-01,\n",
       "          2.3674e-01,  2.4202e-01,  3.9531e-01,  4.6935e-01,  2.9090e-01,\n",
       "          2.7268e-01,  2.7803e-01,  2.9069e-01,  2.0693e-01,  2.5899e-01,\n",
       "          2.7871e-01,  2.9115e-01,  3.1601e-01,  3.8889e-01,  3.0411e-01,\n",
       "          2.6776e-01,  2.1093e-01,  2.8708e-01,  3.3243e-01,  4.2673e-01,\n",
       "          3.7326e-01,  7.4804e-08,  1.9068e-01,  1.4740e-08,  2.2303e-01,\n",
       "          1.7908e-01,  2.4860e-01,  2.7400e-01,  2.5923e-01,  2.9420e-01,\n",
       "          2.9924e-01,  2.2369e-01,  2.6280e-01,  2.2001e-08,  2.6610e-01,\n",
       "          2.2089e-01,  2.8429e-01,  3.3072e-01,  2.2681e-01,  3.6538e-01,\n",
       "          2.1230e-01,  2.3965e-01,  2.4950e-01,  5.2583e-01,  2.4825e-01,\n",
       "          2.9565e-01,  2.5878e-01,  4.8326e-01,  2.6670e-01], device='cuda:0',\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 2.3072e-01,  2.5382e-01, -1.0543e-06, -6.6439e-01, -1.6571e-08,\n",
       "          1.6152e-01,  4.5450e-01, -4.3020e-07,  3.0051e-01, -8.0052e-06,\n",
       "          3.4942e-01,  3.1148e-01, -2.4953e-01, -3.4749e-05,  1.0773e-01,\n",
       "          2.1897e-01,  3.8141e-01, -5.2988e-01, -6.2864e-01,  5.7140e-01,\n",
       "          2.9985e-01,  5.8430e-01,  4.8202e-01,  3.2853e-01,  1.9672e-01,\n",
       "          1.9496e-01,  1.5215e-01,  8.5522e-02,  5.1314e-01,  1.5237e-02,\n",
       "          1.6644e-01,  3.3239e-01,  2.4921e-01,  4.4337e-01, -2.8017e-01,\n",
       "         -2.0385e-02, -2.4507e-07,  3.2134e-01, -4.9152e-08,  2.3777e-01,\n",
       "          2.3291e-01,  3.1527e-01,  4.2776e-01,  2.9313e-01,  2.6379e-01,\n",
       "          6.7598e-01,  4.2910e-01,  3.4566e-01, -8.6909e-08,  2.4729e-01,\n",
       "          3.0316e-01,  6.1577e-01,  3.9835e-01,  3.3207e-01, -4.1219e-01,\n",
       "          3.7807e-01,  1.7895e-01,  2.5748e-01, -4.4908e-01,  2.1306e-01,\n",
       "          5.6934e-01,  5.7274e-01, -4.0238e-01,  2.3406e-01], device='cuda:0',\n",
       "        requires_grad=True), 1e-05)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn.momentum, bn.running_mean, bn.running_var, bn.weight, bn.bias, bn.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-05, momentum=0.1, affine=True):\n",
    "        super(MyBatchNorm, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(num_features,\n",
    "                                 eps=eps,\n",
    "                                 momentum=momentum,\n",
    "                                 affine=affine)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = self.bn(x)\n",
    "        mu = self.bn.running_mean\n",
    "        var = self.bn.running_var\n",
    "        gamma = self.bn.weight\n",
    "        beta = self.bn.bias\n",
    "        eps = self.bn.eps    \n",
    "        k = gamma.data / torch.sqrt(var + eps)\n",
    "        x.data = k * x.data + beta.data\n",
    "        return x\n",
    "\n",
    "mybn = MyBatchNorm(10)\n",
    "x = Variable(torch.randn(16, 10))\n",
    "x_ = mybn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
